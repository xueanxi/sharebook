# 角色提取设计文档

## 1. 概述

本文档描述了一个基于LangGraph的两层架构工作流设计，用于从小说文本中提取角色信息，并将结果保存到CSV文件中。该系统采用外部编排器和内部单章节工作流的分离架构，按章节顺序处理小说，每处理完一个章节就更新CSV文件，支持角色信息的智能合并。系统支持角色别名处理，能够识别和合并同一角色的不同称呼（如全名、昵称、称号等）。

## 2. 系统架构

```mermaid
graph TB
    A[开始] --> B[工作流编排器]
    B --> C[章节选择]
    C --> D[单章节工作流]
    D --> E[文件读取节点]
    E --> F[角色提取节点]
    F --> G[并行角色分析节点]
    G --> H[并行CSV更新节点]
    H --> I[进度检查]
    I --> J{有更多章节?}
    J -->|是| C
    J -->|否| K[结束]
```

## 3. 架构组件

### 3.1 工作流编排器 (CharacterExtractionOrchestrator)

工作流编排器是系统的顶层控制组件，负责：

- 遍历所有章节文件
- 跟踪处理进度
- 为每个章节创建独立的单章节工作流
- 管理配置和状态持久化

### 3.2 单章节工作流 (SingleChapterWorkflow)

单章节工作流是基于LangGraph的独立工作流，负责处理单个章节的完整提取流程：

- 文件读取
- 角色提取
- 并行角色分析
- CSV文件更新

每个章节的处理是独立的，互不影响，提高了系统的稳定性和可恢复性。

## 4. 状态定义

### 4.1 编排器状态

编排器维护全局状态，跟踪所有章节的处理进度：

```python
class OrchestratorState:
    processed_chapters: List[str]  # 已处理的章节列表
    current_chapter: str  # 当前处理的章节
    total_chapters: int  # 总章节数
    error: Optional[str]  # 错误信息
```

### 4.2 单章节工作流状态

```python
class CharacterExtractionState(TypedDict):
    current_chapter: str  # 当前处理的章节文件名
    chapter_content: str  # 章节内容
    extracted_characters: List[Dict]  # 当前章节提取的角色
    all_characters: Dict[str, Dict]  # 所有角色信息（以姓名为键）
    processed_chapters: List[str]  # 已处理的章节列表（单章节工作流中为空）
    csv_path: str  # CSV文件路径
    error: Optional[str]  # 错误信息
    config_path: str  # 配置文件路径
    character_aliases: Dict[str, List[str]]  # 角色别名映射（主名称到别名列表）
    is_completed: bool  # 是否完成所有章节处理
```

## 5. 节点设计

### 5.1 编排器组件

#### 5.1.1 章节选择器 (ChapterSelector)

- **功能**: 获取所有章节列表，支持章节排序
- **位置**: 在编排器层面，不在LangGraph工作流内
- **流程**:
  ```mermaid
  flowchart LR
      A[获取章节列表] --> B[章节排序]
      B --> C[返回章节列表]
  ```

#### 5.1.2 进度检查器 (ProgressChecker)

- **功能**: 检查处理进度，计算完成百分比
- **位置**: 在编排器层面，不在LangGraph工作流内
- **流程**:
  ```mermaid
  flowchart LR
      A[读取已处理章节] --> B[计算总章节数]
      B --> C[计算进度百分比]
      C --> D[返回进度信息]
  ```

### 5.2 单章节工作流节点

#### 5.2.1 文件读取节点 (FileReader)

- **功能**: 读取当前章节文件内容
- **输入**: 章节文件名
- **输出**: 章节内容
- **错误处理**: 文件不存在或读取失败时记录错误
- **验证**: 检查章节内容是否为空或过短

#### 5.2.2 角色提取节点 (CharacterExtractor)

- **功能**: 提取当前章节中的角色信息
- **输入**: 章节内容
- **输出**: 角色列表
- **处理流程**:
  ```mermaid
  flowchart TD
      A[章节内容] --> B[文本预处理]
      B --> C[角色名称识别]
      C --> D[角色列表输出]
  ```
- **验证**: 检查提取结果是否有效
- **预处理**: 对提取的角色信息进行初步处理和格式化
- **LLM提示词**:
  ```
  你是一个专业的小说角色提取专家。请从以下章节文本中提取所有角色名称。
  
  任务要求：
  1. 识别文本中提到的所有角色名称（包括主角、配角、反派等）
  2. 忽略无明确名称的泛指角色（如"路人甲"、"众人"等）
  3. 只返回明确有姓名或称号的角色
  4. 对于每个角色，尽可能识别其可能的别名、昵称或称号
  
  输出格式：
  [
    {
      "name": "角色名称",
      "aliases": ["别名1", "别名2", ...]  // 可选，如果没有别名则为空列表
    },
    ...
  ]
  
  章节文本：
  {chapter_content}
  ```

#### 5.2.3 并行角色分析节点 (ParallelCharacterAnalyzer)

- **功能**: 并行对提取的角色进行深度分析
- **输入**: 基础角色列表
- **输出**: 详细角色信息
- **并行处理流程**:
  ```mermaid
  graph TB
      A[角色列表] --> B[任务分发器]
      B --> C[角色分析Agent 1]
      B --> D[角色分析Agent 2]
      B --> E[角色分析Agent 3]
      B --> F[角色分析Agent 4]
      B --> G[角色分析Agent 5]
      B --> H[角色分析Agent 6]
      C --> I[结果收集器]
      D --> I
      E --> I
      F --> I
      G --> I
      H --> I
      I --> J[信息整合]
  ```
- **并行限制**: 最多同时存在6个角色分析Agent
- **任务分配**: 每个Agent负责一个角色的全面分析
- **完成条件**: 所有角色都完成分析后进入下一节点
- **验证**: 检查分析结果是否完整和有效
- **角色分析Agent提示词**:
  ```
  你是一个专业的小说角色分析专家。请对以下角色进行全面分析。
  
  角色信息：
  - 姓名：{character_name}
  - 别名：{character_aliases}  // 如果有别名的话
  
  任务要求：
  1. 判断角色性别（男/女/未知）
  2. 提取外貌特征（发型、面容、身材等，50字以内）
  3. 提取服装特点（衣着风格、特殊装饰等，50字以内）
  4. 判断角色类型（主角/配角/反派/其他）
  5. 整合和补充别名信息（如果有）
  
  输出格式（JSON）：
  {
    "性别": "男/女/未知",
    "外貌特征": "外貌描述（50字以内）",
    "服装特点": "服装描述（50字以内）",
    "角色类型": "主角/配角/反派/其他",
    "别名": ["别名1", "别名2", ...]  // 如果没有别名则为空列表
  }
  
  注意：如果某项信息不明确，请填写"未知"。保持描述简洁准确。
  ```

#### 5.2.4 并行CSV更新节点 (ParallelCSVUpdater)

- **功能**: 并行处理角色信息并更新CSV文件
- **输入**: 详细角色信息
- **输出**: 更新后的CSV文件
- **处理流程**:
  ```mermaid
  flowchart TD
      A[角色信息列表] --> B[读取现有CSV]
      B --> C[Python筛选角色]
      C --> D{角色是否已存在?}
      D -->|不存在| E[直接插入新角色]
      D -->|存在| F[需要合并的角色列表]
      E --> G[收集新角色]
      F --> H[并行处理需要合并的角色]
      H --> I[任务分发器]
      I --> J[CSV更新Agent 1]
      I --> K[CSV更新Agent 2]
      I --> L[CSV更新Agent 3]
      I --> M[CSV更新Agent 4]
      I --> N[CSV更新Agent 5]
      I --> O[CSV更新Agent 6]
      J --> P[结果收集器]
      K --> P
      L --> P
      M --> P
      N --> P
      O --> P
      G --> Q[合并所有结果]
      P --> Q
      Q --> R[统一更新CSV文件]
  ```
- **并行限制**: 最多同时存在6个CSV更新Agent
- **任务分配**: 每个Agent负责处理一个需要合并的角色信息
- **完成条件**: 所有角色处理完成后，统一更新CSV文件
- **验证**: 检查CSV更新是否成功
- **角色筛选逻辑**:
  1. **角色分类**: 使用Python代码基于姓名和别名精确匹配将角色分为两类：
     - 新角色：CSV中不存在的角色（包括主名称和所有别名都不匹配），直接插入
     - 已存在角色：CSV中已存在的角色（主名称或任一别名匹配），需要合并处理
  2. **新角色处理**: 直接添加新角色信息到结果集
  3. **已存在角色处理**: 并行调用LLM进行智能信息合并
- **CSV更新Agent提示词**:
  ```
  你是一个专业的角色信息整合专家。请根据已有信息和新信息，合并角色数据。
  
  已有角色信息：
  {existing_character_info}
  
  新角色信息：
  {new_character_info}
  
  任务要求：
  1. 智能合并新旧信息：
     - 优先保留更详细、更准确的描述
     - 去除重复信息
     - 补充缺失信息
     - 保持描述简洁（每项不超过50字）
  2. 确保合并后的信息逻辑一致
  3. 合并别名信息，去除重复，保持唯一性
  
  输出格式（JSON）：
  {
    "姓名": "角色姓名",
    "性别": "男/女/未知",
    "外貌特征": "外貌描述（50字以内）",
    "服装特点": "服装描述（50字以内）",
    "角色类型": "主角/配角/反派/其他",
    "别名": ["别名1", "别名2", ...]  // 如果没有别名则为空列表
  }
  
  注意：如果某项信息不明确，请填写"未知"。保持描述简洁准确。
  ```

### 5.3 配置文件设计

系统使用`config.yaml`配置文件管理所有设置和进度信息：

```yaml
# 角色提取配置文件
extraction:
  # 当前处理进度
  progress:
    current_chapter: ""  # 当前处理的章节文件名
    processed_chapters: []  # 已处理的章节列表
    last_update_time: ""  # 最后更新时间
    
  # 文件路径配置
  paths:
    novel_path: "data/cleaned_novel"  # 小说文件目录
    csv_path: "data/characters/characters.csv"  # 输出CSV文件路径
    config_path: "src/services/extraction_character/config.yaml"  # 配置文件路径
    
  # 并行处理配置
  parallel:
    max_analyzer_agents: 6  # 角色分析最大并行agent数
    max_csv_agents: 6  # CSV更新最大并行agent数
    
  # 错误处理配置
  error_handling:
    retry_count: 3  # 失败重试次数
    log_errors: true  # 是否记录错误日志
    
  # LLM配置
  llm:
    config_path: "config/llm_config.py"  # LLM配置文件路径
    temperature: 0.4  # LLM温度参数（与llm_config.py保持一致）
    max_tokens: 2000  # 最大生成token数（与llm_config.py保持一致）
    timeout: 30  # 请求超时时间（与llm_config.py保持一致）
```

### 配置管理器 (ConfigManager)

配置管理器负责配置文件的读取、更新和持久化：

- **初始化**: 检查配置文件是否存在，不存在则创建默认配置
- **进度更新**: 每完成一个章节处理后更新配置文件中的进度信息
- **恢复机制**: 系统中断重启后，从配置文件读取进度，从中断点继续处理
- **配置修改**: 支持运行时修改配置参数，如并行agent数量等

### 配置文件更新机制

1. **更新频率**:
   - 每完成一个章节处理后立即更新配置文件
   - 系统启动时读取配置文件获取上次处理进度
   - 配置参数修改后立即保存到配置文件

2. **原子性更新**:
   - 使用临时文件写入，然后原子性替换原文件
   - 防止写入过程中断导致配置损坏

3. **配置文件备份**:
   - 每次更新前自动创建备份
   - 保留最近5个配置文件备份

## 6. 智能角色信息合并策略

对于已存在的角色，使用Python代码进行判断，然后调用LLM进行信息合并：

```mermaid
flowchart TD
    A[角色信息列表] --> B[读取现有CSV]
    B --> C[Python筛选角色]
    C --> D{角色是否已存在?}
    D -->|不存在| E[直接插入新角色]
    D -->|存在| F[需要合并的角色列表]
    E --> G[收集新角色]
    F --> H[并行处理需要合并的角色]
    H --> I[任务分发器]
    I --> J[CSV更新Agent 1]
    I --> K[CSV更新Agent 2]
    I --> L[CSV更新Agent 3]
    I --> M[CSV更新Agent 4]
    I --> N[CSV更新Agent 5]
    I --> O[CSV更新Agent 6]
    J --> P[结果收集器]
    K --> P
    L --> P
    M --> P
    N --> P
    O --> P
    G --> Q[合并所有结果]
    P --> Q
    Q --> R[统一更新CSV文件]
    
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style H fill:#bbf,stroke:#333,stroke-width:2px
```

### 合并逻辑

1. **角色分类**: 使用Python代码基于姓名和别名精确匹配将角色分为两类：
   - 新角色：CSV中不存在的角色（包括主名称和所有别名都不匹配），直接插入
   - 已存在角色：CSV中已存在的角色（主名称或任一别名匹配），需要合并处理

2. **新角色处理**: 直接添加新角色信息到结果集，无需LLM调用

3. **已存在角色处理**: 并行调用LLM进行智能信息合并，最多6个并行Agent

### 合并提示词设计

```python
def merge_character_info(existing_info: Dict, new_info: Dict) -> Dict:
    """使用LLM智能合并角色信息，保持简洁"""
    prompt = f"""
    你是一个专业的角色信息整合专家。请根据已有信息和新信息，合并角色数据。
    
    已有角色信息：
    {existing_info}
    
    新角色信息：
    {new_info}
    
    任务要求：
    1. 智能合并新旧信息：
       - 优先保留更详细、更准确的描述
       - 去除重复信息
       - 补充缺失信息
       - 保持描述简洁（每项不超过50字）
    2. 确保合并后的信息逻辑一致
    3. 合并别名信息，去除重复，保持唯一性
    
    输出格式（JSON）：
    {{
      "姓名": "角色姓名",
      "性别": "男/女/未知",
      "外貌特征": "外貌描述（50字以内）",
      "服装特点": "服装描述（50字以内）",
      "角色类型": "主角/配角/反派/其他",
      "别名": ["别名1", "别名2", ...]  // 如果没有别名则为空列表
    }}
    
    注意：如果某项信息不明确，请填写"未知"。保持描述简洁准确。
    """
    # 调用LLM处理并返回结果
```

### LLM配置说明

所有LLM调用统一使用`config/llm_config.py`中的配置，包括：
- API基础地址和模型名称
- 请求超时时间和重试次数
- 温度参数和其他模型参数

这确保了整个系统中LLM调用的一致性，便于统一管理和调整。

## 7. CSV文件格式

CSV文件包含以下列：

| 列名 | 描述 | 示例 |
|------|------|------|
| 姓名 | 角色名称 | 叶君临 |
| 性别 | 角色 性别 | 男 |
| 外貌特征 | 外观描述 | 银白色长发，黑袍，剑眉星目 |
| 服装特点 | 服装描述 | 黑色长袍 |
| 角色类型 | 角色 分类 | 主角 |
| 别名 | 角色别名、昵称、称号 | 君临|叶公子|剑仙|

### CSV文件示例

```csv
姓名,性别,外貌特征,服装特点,角色类型,别名
张三,男,高大英俊，黑发棕眼,常穿蓝色西装，白色衬衫,主角,
李四,女,苗条美丽，长发及腰,喜欢穿红色连衣裙,配角,小丽|丽丽
王五,男,中等身材，戴着眼镜,总是穿着灰色外套,配角,老王|王老师
```

### 别名列说明

- 别名列使用竖线"|"分隔多个别名
- 如果角色没有别名，该列为空
- 别名包括昵称、称号、简称等角色的不同称呼
- 别名信息在角色合并时会被智能合并，去除重复

## 8. 错误处理与恢复机制

```mermaid
flowchart TD
    A[节点执行] --> B{是否发生错误?}
    B -->|否| C[继续下一个节点]
    B -->|是| D[记录错误信息]
    D --> E{是否可恢复?}
    E -->|是| F[执行恢复操作]
    E -->|否| G[终止流程]
    F --> H[重试当前节点]
    H --> B
```

### 恢复策略

1. **章节级别恢复**: 记录已处理的章节，支持从中断点恢复
2. **节点级别重试**: 对可恢复错误实施自动重试
3. **错误日志**: 详细记录错误信息，便于调试
4. **别名处理错误恢复**: 当别名处理失败时，保留主名称信息，确保核心数据不丢失

## 9. 性能优化

1. **并行处理**: 角色分析和CSV更新阶段使用并行处理提高效率
   - 角色分析阶段最多6个并行agent
   - CSV更新阶段最多6个并行agent
2. **缓存机制**: 缓存已处理的章节信息和角色分析结果
3. **批量操作**: 所有角色处理完成后统一更新CSV文件，减少I/O操作
4. **配置驱动**: 通过配置文件灵活调整并行参数，适应不同硬件环境
5. **别名索引优化**: 建立别名到主名称的映射索引，加速角色匹配过程

## 10. 部署与执行

### 执行流程

```mermaid
sequenceDiagram
    participant User as 用户
    participant Orchestrator as 工作流编排器
    participant Config as 配置管理
    participant ChapterWorkflow as 单章节工作流
    participant FileReader as 文件读取
    participant Extractor as 角色提取
    participant Analyzer as 并行角色分析
    participant CSV as 并行CSV更新
    
    User->>Orchestrator: 启动角色提取
    Orchestrator->>Config: 读取配置文件
    Config-->>Orchestrator: 返回配置和进度
    loop 每个章节
        Orchestrator->>ChapterWorkflow: 创建单章节工作流
        ChapterWorkflow->>FileReader: 读取章节
        FileReader-->>ChapterWorkflow: 返回内容
        ChapterWorkflow->>Extractor: 提取角色
        Extractor-->>ChapterWorkflow: 返回角色列表(含别名)
        ChapterWorkflow->>Analyzer: 并行分析角色
        par 最多6个并行agent
            Analyzer->>Analyzer: 处理角色1
        and
            Analyzer->>Analyzer: 处理角色2
        and
            Analyzer->>Analyzer: 处理角色N
        end
        Analyzer-->>ChapterWorkflow: 返回详细信息(含别名)
        ChapterWorkflow->>CSV: 并行处理角色信息
        Note over CSV: 第一步：Python筛选角色
        CSV->>CSV: 读取现有CSV
        CSV->>CSV: 基于姓名和别名匹配分类角色
        Note over CSV: 第二步：直接插入新角色
        CSV->>CSV: 收集新角色信息
        Note over CSV: 第三步：并行处理需要合并的角色
        par 最多6个并行agent
            CSV->>CSV: 处理需要合并的角色1
        and
            CSV->>CSV: 处理需要合并的角色2
        and
            CSV->>CSV: 处理需要合并的角色N
        end
        Note over CSV: 第四步：合并结果并更新CSV
        CSV->>CSV: 合并新角色和合并后的角色
        CSV-->>ChapterWorkflow: 统一更新CSV
        ChapterWorkflow-->>Orchestrator: 返回处理结果
        Orchestrator->>Config: 更新进度信息
    end
    Orchestrator-->>User: 完成提取
```

## 11. 配置参数

| 参数名 | 类型 | 默认值 | 描述 |
|--------|------|--------|------|
| novel_path | str | data/cleaned_novel | 小说文件目录 |
| csv_path | str | data/characters/characters.csv | 输出CSV文件路径 |
| config_path | str | src/services/extraction_character/config.yaml | 配置文件路径 |
| max_analyzer_agents | int | 6 | 角色分析最大并行agent数 |
| max_csv_agents | int | 6 | CSV更新最大并行agent数 |
| llm_config_path | str | config/llm_config.py | LLM配置文件路径 |
| llm_temperature | float | 0.4 | LLM温度参数（与llm_config.py保持一致） |
| llm_max_tokens | int | 2000 | 最大生成token数（与llm_config.py保持一致） |
| llm_timeout | int | 30 | 请求超时时间（与llm_config.py保持一致） |
| retry_count | int | 3 | 失败重试次数 |
| log_errors | bool | true | 是否记录错误日志 |
| enable_alias_matching | bool | true | 是否启用别名匹配 |
| min_alias_similarity | float | 0.8 | 别名相似度阈值（0-1） |
| max_aliases_per_character | int | 10 | 每个角色最大别名数量 |

### LLM配置说明

所有LLM调用统一使用`config/llm_config.py`中的配置，包括：
- API基础地址和模型名称
- 请求超时时间和重试次数
- 温度参数和其他模型参数

这确保了整个系统中LLM调用的一致性，便于统一管理和调整。

## 12. 实现注意事项

1. **配置文件管理**: 
   - 确保配置文件的原子性更新，避免写入过程中断导致配置损坏
   - 定期备份配置文件，防止意外丢失

2. **并行处理限制**:
   - 角色分析和CSV更新阶段的并行agent数量应根据系统资源动态调整
   - 实现任务队列机制，确保高负载时的系统稳定性

3. **错误处理**:
   - 单个角色分析失败不应影响其他角色的处理
   - CSV更新失败时应有回滚机制，保证数据一致性

4. **性能监控**:
   - 记录各阶段的处理时间，便于性能优化
   - 监控并行agent的资源使用情况，防止系统过载

### CSV文件备份机制

确保数据安全，系统实现了简单的CSV文件备份机制：

1. **自动备份策略**:
   - 每次更新CSV文件前，自动创建备份
   - 备份文件命名格式：`characters_backup_YYYYMMDD_HHMMSS.csv`
   - 备份文件存储位置：与CSV文件相同的目录

2. **备份实现代码**:
   ```python
   import os
   import shutil
   from datetime import datetime
   
   def create_csv_backup(csv_path: str) -> str:
       """
       创建CSV文件的备份
       返回备份文件路径
       """
       try:
           # 获取当前时间戳
           timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
           
           # 构建备份文件名
           dir_name = os.path.dirname(csv_path)
           base_name = os.path.basename(csv_path)
           name, ext = os.path.splitext(base_name)
           backup_filename = f"{name}_backup_{timestamp}{ext}"
           backup_path = os.path.join(dir_name, backup_filename)
           
           # 创建备份
           shutil.copy2(csv_path, backup_path)
           
           return backup_path
       except Exception as e:
           log_error(f"CSV备份创建失败: {e}")
           return ""
   ```

## 13. 代码结构与实现细节

### 13.1 主要文件结构

```
src/services/extraction_character/
├── main.py                    # 主入口脚本
├── workflow_orchestrator.py   # 工作流编排器
├── single_chapter_workflow.py # 单章节工作流
├── state.py                   # 状态定义
├── config_manager.py          # 配置管理器
├── config.yaml               # 配置文件
├── nodes/                    # 节点实现
│   ├── chapter_selector.py   # 章节选择器
│   ├── file_reader.py        # 文件读取
│   ├── character_extractor.py # 角色提取
│   ├── parallel_analyzer.py  # 并行角色分析
│   ├── parallel_csv_updater.py # 并行CSV更新
│   └── progress_checker.py   # 进度检查
└── utils/                    # 工具函数
    └── backup_utils.py       # 备份工具
```

### 13.2 关键实现特点

1. **两层架构分离**:
   - 编排器负责外部循环和进度管理
   - 单章节工作流负责具体的处理逻辑
   - 提高了系统的模块化和可维护性

2. **独立的工作流实例**:
   - 每个章节使用独立的工作流实例
   - 章节间处理相互独立，提高稳定性
   - 单个章节处理失败不影响其他章节

3. **状态隔离**:
   - 编排器状态和单章节工作流状态分离
   - 避免了状态混淆和潜在的数据一致性问题

4. **错误隔离**:
   - 单个章节的错误不会影响整体流程
   - 支持继续处理下一章节或中断处理